{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from src.dataset import ParityPredictionDataset, HiddenParityPrediction\n",
    "from src.model import TinyModel, TinyTransformer\n",
    "from src.train import train_model\n",
    "from src.plot import (\n",
    "    plot_losses,\n",
    "    plot_accuracies,\n",
    "    plot_line_with_label,\n",
    "    plot_list_of_lines_and_labels,\n",
    ")\n",
    "from src.common import get_accuracy_on_dataset\n",
    "\n",
    "weight_decay = 1e-2\n",
    "learning_rate = 1e-1\n",
    "batch_size = 32\n",
    "hidden_size = 1000\n",
    "number_samples = 770\n",
    "epochs = 400\n",
    "\n",
    "# Replicability\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 693\n",
      "Validation dataset size: 77\n"
     ]
    }
   ],
   "source": [
    "# Create the training dataset\n",
    "entire_dataset = HiddenParityPrediction(\n",
    "    num_samples=number_samples,\n",
    "    sequence_length=40,\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "# Split into training and validation should be 1000 and 100\n",
    "train_size = int(0.90 * number_samples)\n",
    "val_size = number_samples - train_size\n",
    "training_dataset, validation_dataset = torch.utils.data.random_split(\n",
    "    entire_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Training dataset size: {len(training_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TransformerModel.__init__() got an unexpected keyword argument 'hidden_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m         x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpe[:x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), :]\n\u001b[1;32m     48\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[0;32m---> 50\u001b[0m model \u001b[39m=\u001b[39m TransformerModel(\n\u001b[1;32m     51\u001b[0m     input_size\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[1;32m     52\u001b[0m     hidden_size\u001b[39m=\u001b[39;49mhidden_size,\n\u001b[1;32m     53\u001b[0m     output_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     54\u001b[0m     nhead\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     55\u001b[0m     nlayers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     56\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: TransformerModel.__init__() got an unexpected keyword argument 'hidden_size'"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, nhead, nlayers):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(self.hidden_size)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=self.hidden_size, nhead=nhead),\n",
    "            num_layers=nlayers,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(self.input_size * self.hidden_size, self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.output_size, bias=False)\n",
    "        \n",
    "        # Initialise weights\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.flatten(start_dim=1)\n",
    "        output = torch.relu(self.fc1(output))\n",
    "        output = self.fc2(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "model = TransformerModel(\n",
    "    input_size=40,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=1,\n",
    "    nhead=1,\n",
    "    nlayers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size = torch.Size([32, 40]), target size = torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[1;32m      2\u001b[0m     model,\n\u001b[1;32m      3\u001b[0m     training_losses,\n\u001b[1;32m      4\u001b[0m     validation_losses,\n\u001b[1;32m      5\u001b[0m     training_accuracy,\n\u001b[1;32m      6\u001b[0m     validation_accuracy,\n\u001b[1;32m      7\u001b[0m     _,\n\u001b[0;32m----> 8\u001b[0m ) \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m      9\u001b[0m     training_dataset\u001b[39m=\u001b[39;49mtraining_dataset,\n\u001b[1;32m     10\u001b[0m     validation_dataset\u001b[39m=\u001b[39;49mvalidation_dataset,\n\u001b[1;32m     11\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     12\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     13\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m     14\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     15\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     16\u001b[0m     loss_function_label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhinge\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m     optimiser_function_label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msgd\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m     progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32m~/tiny-gen/src/train.py:78\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(training_dataset, validation_dataset, model, learning_rate, weight_decay, epochs, batch_size, loss_function_label, optimiser_function_label, progress_bar, generalisation_dataset)\u001b[0m\n\u001b[1;32m     76\u001b[0m targets \u001b[39m=\u001b[39m batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput size = \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m, target size = \u001b[39m\u001b[39m{\u001b[39;00mtargets\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m predictions \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     80\u001b[0m loss \u001b[39m=\u001b[39m loss_function(predictions, targets)\n\u001b[1;32m     82\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny-gen/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mTestTransformer.forward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(src) \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\n\u001b[1;32m     31\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder(src)\n\u001b[0;32m---> 32\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(src, src_mask)\n\u001b[1;32m     33\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(output)\n\u001b[1;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny-gen/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny-gen/lib/python3.11/site-packages/torch/nn/modules/transformer.py:137\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Take in and process masked source/target sequences.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m    >>> output = transformer_model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m is_batched \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m--> 137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m src\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m tgt\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39m) \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m    138\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mthe batch number of src and tgt must be equal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m src\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m!=\u001b[39m tgt\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mand\u001b[39;00m is_batched:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "(\n",
    "    model,\n",
    "    training_losses,\n",
    "    validation_losses,\n",
    "    training_accuracy,\n",
    "    validation_accuracy,\n",
    "    _,\n",
    ") = train_model(\n",
    "    training_dataset=training_dataset,\n",
    "    validation_dataset=validation_dataset,\n",
    "    model=model,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    loss_function_label=\"hinge\",\n",
    "    optimiser_function_label=\"sgd\",\n",
    "    progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
